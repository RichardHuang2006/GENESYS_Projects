{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "395c4a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Train Acc: 0.4390, Val Acc: 0.4359, Train Loss: 1.3776, Val Loss: 1.3381\n",
      "[Epoch 2] Train Acc: 0.5696, Val Acc: 0.4786, Train Loss: 1.0637, Val Loss: 1.3038\n",
      "[Epoch 3] Train Acc: 0.6638, Val Acc: 0.4701, Train Loss: 0.8487, Val Loss: 1.4845\n",
      "[Epoch 4] Train Acc: 0.7152, Val Acc: 0.4274, Train Loss: 0.7320, Val Loss: 1.4464\n",
      "[Epoch 5] Train Acc: 0.8351, Val Acc: 0.4701, Train Loss: 0.4298, Val Loss: 1.5464\n",
      "Saved best model at epoch 6 (Val Acc = 0.5043)\n",
      "[Epoch 6] Train Acc: 0.9593, Val Acc: 0.5043, Train Loss: 0.1579, Val Loss: 1.7744\n",
      "[Epoch 7] Train Acc: 0.9850, Val Acc: 0.4957, Train Loss: 0.0499, Val Loss: 1.9086\n",
      "[Epoch 8] Train Acc: 0.9850, Val Acc: 0.4872, Train Loss: 0.0565, Val Loss: 1.9697\n",
      "[Epoch 9] Train Acc: 0.9936, Val Acc: 0.4274, Train Loss: 0.0269, Val Loss: 2.0762\n",
      "[Epoch 10] Train Acc: 0.9979, Val Acc: 0.4188, Train Loss: 0.0120, Val Loss: 2.0949\n",
      "[Epoch 11] Train Acc: 1.0000, Val Acc: 0.4359, Train Loss: 0.0061, Val Loss: 2.1304\n",
      "[Epoch 12] Train Acc: 1.0000, Val Acc: 0.4444, Train Loss: 0.0052, Val Loss: 2.1664\n",
      "[Epoch 13] Train Acc: 1.0000, Val Acc: 0.4530, Train Loss: 0.0044, Val Loss: 2.1811\n",
      "[Epoch 14] Train Acc: 1.0000, Val Acc: 0.4530, Train Loss: 0.0041, Val Loss: 2.1952\n",
      "[Epoch 15] Train Acc: 1.0000, Val Acc: 0.4530, Train Loss: 0.0039, Val Loss: 2.2086\n",
      "[Epoch 16] Train Acc: 1.0000, Val Acc: 0.4444, Train Loss: 0.0037, Val Loss: 2.2157\n",
      "[Epoch 17] Train Acc: 1.0000, Val Acc: 0.4444, Train Loss: 0.0036, Val Loss: 2.2226\n",
      "[Epoch 18] Train Acc: 1.0000, Val Acc: 0.4444, Train Loss: 0.0035, Val Loss: 2.2297\n",
      "[Epoch 19] Train Acc: 1.0000, Val Acc: 0.4444, Train Loss: 0.0034, Val Loss: 2.2331\n",
      "[Epoch 20] Train Acc: 1.0000, Val Acc: 0.4530, Train Loss: 0.0033, Val Loss: 2.2366\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "# --------------------- Dataset ---------------------\n",
    "\n",
    "class ImageArrayDataset(Dataset):\n",
    "    def __init__(self, samples, transform=None):\n",
    "        self.samples = samples\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, npy_path = self.samples[idx]\n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Failed to open image {img_path}: {e}\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label_array = np.load(npy_path)\n",
    "        assert label_array.ndim == 1, f\"Invalid label shape in {npy_path}\"\n",
    "        label = int(np.argmax(label_array))\n",
    "        return image, label\n",
    "\n",
    "# --------------------- Data Loading ---------------------\n",
    "\n",
    "def load_samples(folder_path):\n",
    "    samples = []\n",
    "    for fname in os.listdir(folder_path):\n",
    "        if fname.lower().endswith(('.jpg', '.png')):\n",
    "            base = os.path.splitext(fname)[0]\n",
    "            img_path = os.path.join(folder_path, fname)\n",
    "            npy_path = os.path.join(folder_path, base + '.npy')\n",
    "            if os.path.exists(npy_path):\n",
    "                samples.append((img_path, npy_path))\n",
    "    return samples\n",
    "\n",
    "def prepare_combined_loaders(folders, val_split=0.2, batch_size=16, seed=42):\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    all_samples = []\n",
    "    for folder in folders:\n",
    "        all_samples.extend(load_samples(folder))\n",
    "\n",
    "    random.shuffle(all_samples)\n",
    "    split = int(len(all_samples) * (1 - val_split))\n",
    "    train_samples = all_samples[:split]\n",
    "    val_samples = all_samples[split:]\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    train_dataset = ImageArrayDataset(train_samples, transform=transform)\n",
    "    val_dataset = ImageArrayDataset(val_samples, transform=transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    return train_loader, val_loader\n",
    "\n",
    "# --------------------- Training ---------------------\n",
    "\n",
    "def train(model, train_loader, val_loader, criterion, optimizer, scheduler, device, epochs, save_path, threshold):\n",
    "    best_val_acc = 0.0\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss, correct, total = 0.0, 0, 0\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * imgs.size(0)\n",
    "            correct += (outputs.argmax(1) == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "        train_acc = correct / total\n",
    "        train_loss /= total\n",
    "\n",
    "        model.eval()\n",
    "        val_loss, correct, total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in val_loader:\n",
    "                imgs, labels = imgs.to(device), labels.to(device)\n",
    "                outputs = model(imgs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * imgs.size(0)\n",
    "                correct += (outputs.argmax(1) == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "        val_acc = correct / total\n",
    "        val_loss /= total\n",
    "        scheduler.step(val_acc)\n",
    "\n",
    "        if val_acc >= threshold and val_acc >= best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"Saved best model at epoch {epoch+1} (Val Acc = {val_acc:.4f})\")\n",
    "\n",
    "        print(f\"[Epoch {epoch+1}] Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}, \"\n",
    "              f\"Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "# --------------------- Main ---------------------\n",
    "\n",
    "def main():\n",
    "    folders = [\n",
    "        r\"C:\\Users\\huang\\Downloads\\Engineering Projects\\Genesys Lab\\v5\",\n",
    "        r\"C:\\Users\\huang\\Downloads\\Engineering Projects\\Genesys Lab\\v6\"\n",
    "    ]\n",
    "    batch_size = 16\n",
    "    epochs = 20\n",
    "    val_threshold = 0.5\n",
    "    seed = 42\n",
    "\n",
    "    train_loader, val_loader = prepare_combined_loaders(folders, val_split=0.2, batch_size=batch_size, seed=seed)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = timm.create_model('vit_tiny_patch16_224', pretrained=True, num_classes=5).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=2, factor=0.5)\n",
    "\n",
    "    train(model, train_loader, val_loader, criterion, optimizer, scheduler, device,\n",
    "          epochs, save_path='vit_tiny_combined_best.pth', threshold=val_threshold)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
